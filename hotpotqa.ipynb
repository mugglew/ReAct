{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import openai\n",
    " \n",
    "#openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "#openai.api_key = \"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\"\n",
    "\n",
    "def llm(prompt, stop=[\"\\n\"]):\n",
    "    client = OpenAI(api_key=\"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\")\n",
    "    response = client.completions.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt,\n",
    "      temperature=0,\n",
    "      max_tokens=100,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.0,\n",
    "      stop=stop\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikienv, wrappers\n",
    "env = wikienv.WikiEnv()\n",
    "env = wrappers.HotPotQAWrapper(env, split=\"dev\")\n",
    "env = wrappers.LoggingWrapper(env)\n",
    "\n",
    "def step(env, action):\n",
    "    attempts = 0\n",
    "    while attempts < 10:\n",
    "        try:\n",
    "            return env.step(action)\n",
    "        except requests.exceptions.Timeout:\n",
    "            attempts += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "folder = './prompts/'\n",
    "prompt_file = 'prompts_naive.json'\n",
    "with open(folder + prompt_file, 'r') as f:\n",
    "    prompt_dict = json.load(f)\n",
    "\n",
    "webthink_examples = prompt_dict['webthink_simple6']\n",
    "instruction = \"\"\"Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types: \n",
    "(1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search.\n",
    "(2) Lookup[keyword], which returns the next sentence containing keyword in the current passage.\n",
    "(3) Finish[answer], which returns the answer and finishes the task.\n",
    "Here are some examples.\n",
    "\"\"\"\n",
    "webthink_prompt = instruction + webthink_examples\n",
    "\n",
    "def webthink(idx=None, prompt=webthink_prompt, to_print=True):\n",
    "    question = env.reset(idx=idx)\n",
    "    if to_print:\n",
    "        print(idx, question)\n",
    "    prompt += question + \"\\n\"\n",
    "    n_calls, n_badcalls = 0, 0\n",
    "    for i in range(1, 8):\n",
    "        n_calls += 1\n",
    "        thought_action = llm(prompt + f\"Thought {i}:\", stop=[f\"\\nObservation {i}:\"])\n",
    "        try:\n",
    "            thought, action = thought_action.strip().split(f\"\\nAction {i}: \")\n",
    "        except:\n",
    "            print('ohh...', thought_action)\n",
    "            n_badcalls += 1\n",
    "            n_calls += 1\n",
    "            thought = thought_action.strip().split('\\n')[0]\n",
    "            action = llm(prompt + f\"Thought {i}: {thought}\\nAction {i}:\", stop=[f\"\\n\"]).strip()\n",
    "        obs, r, done, info = step(env, action[0].lower() + action[1:])\n",
    "        obs = obs.replace('\\\\n', '')\n",
    "        step_str = f\"Thought {i}: {thought}\\nAction {i}: {action}\\nObservation {i}: {obs}\\n\"\n",
    "        prompt += step_str\n",
    "        if to_print:\n",
    "            print(step_str)\n",
    "        if done:\n",
    "            break\n",
    "    if not done:\n",
    "        obs, r, done, info = step(env, \"finish[]\")\n",
    "    if to_print:\n",
    "        print(info, '\\n')\n",
    "    info.update({'n_calls': n_calls, 'n_badcalls': n_badcalls, 'traj': prompt})\n",
    "    return r, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3687 Question: What movie did actress Irene Jacob complete before the American action crime thriller film directed by Stuart Bird?\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'The OpenAI account associated with this API key has been deactivated. If you are the developer for this OpenAI app, please check your email for more information. If you are seeing this error while using another app or site, please reach out to them for more help.', 'type': 'invalid_request_error', 'param': None, 'code': 'account_deactivated'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/ReAct/hotpotqa.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m old_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idxs[:\u001b[39m500\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     r, info \u001b[39m=\u001b[39m webthink(i, to_print\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     rs\u001b[39m.\u001b[39mappend(info[\u001b[39m'\u001b[39m\u001b[39mem\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     infos\u001b[39m.\u001b[39mappend(info)\n",
      "\u001b[1;32m/workspaces/ReAct/hotpotqa.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     n_calls \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     thought_action \u001b[39m=\u001b[39m llm(prompt \u001b[39m+\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mThought \u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m\"\u001b[39;49m, stop\u001b[39m=\u001b[39;49m[\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mObservation \u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m:\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m         thought, action \u001b[39m=\u001b[39m thought_action\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAction \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/workspaces/ReAct/hotpotqa.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mllm\u001b[39m(prompt, stop\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     client \u001b[39m=\u001b[39m OpenAI(api_key\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msk-LWDCw7kH4YJ8yfWSD686T3BlbkFJ3KSpiaCW9lFC0h52BStW\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mcompletions\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m       prompt\u001b[39m=\u001b[39;49mprompt,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m       temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m       max_tokens\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m       top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m       frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m       presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0.0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m       stop\u001b[39m=\u001b[39;49mstop\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsilver-giggle-49g75g57v737557/workspaces/ReAct/hotpotqa.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_utils/_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/resources/completions.py:559\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, model, prompt, best_of, echo, frequency_penalty, logit_bias, logprobs, max_tokens, n, presence_penalty, seed, stop, stream, suffix, temperature, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39m@required_args\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m], [\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprompt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    519\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    558\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Completion \u001b[39m|\u001b[39m Stream[Completion]:\n\u001b[0;32m--> 559\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[1;32m    560\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    561\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[1;32m    562\u001b[0m             {\n\u001b[1;32m    563\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[1;32m    564\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mprompt\u001b[39;49m\u001b[39m\"\u001b[39;49m: prompt,\n\u001b[1;32m    565\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mbest_of\u001b[39;49m\u001b[39m\"\u001b[39;49m: best_of,\n\u001b[1;32m    566\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mecho\u001b[39;49m\u001b[39m\"\u001b[39;49m: echo,\n\u001b[1;32m    567\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[1;32m    568\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[1;32m    569\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[1;32m    570\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[1;32m    571\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[1;32m    572\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[1;32m    573\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[1;32m    574\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[1;32m    575\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[1;32m    576\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39msuffix\u001b[39;49m\u001b[39m\"\u001b[39;49m: suffix,\n\u001b[1;32m    577\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[1;32m    578\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[1;32m    579\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[1;32m    580\u001b[0m             },\n\u001b[1;32m    581\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[1;32m    582\u001b[0m         ),\n\u001b[1;32m    583\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[1;32m    584\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    585\u001b[0m         ),\n\u001b[1;32m    586\u001b[0m         cast_to\u001b[39m=\u001b[39;49mCompletion,\n\u001b[1;32m    587\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    588\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[Completion],\n\u001b[1;32m    589\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[1;32m   1042\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1043\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1051\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[1;32m   1052\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[1;32m   1053\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[0;32m-> 1055\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    826\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    832\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    833\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m--> 834\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[1;32m    835\u001b[0m         cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[1;32m    836\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    837\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    838\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[1;32m    839\u001b[0m         remaining_retries\u001b[39m=\u001b[39;49mremaining_retries,\n\u001b[1;32m    840\u001b[0m     )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/openai/_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[39m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     \u001b[39m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 877\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m httpx\u001b[39m.\u001b[39mTimeoutException \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    879\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'The OpenAI account associated with this API key has been deactivated. If you are the developer for this OpenAI app, please check your email for more information. If you are seeing this error while using another app or site, please reach out to them for more help.', 'type': 'invalid_request_error', 'param': None, 'code': 'account_deactivated'}}"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "idxs = list(range(7405))\n",
    "random.Random(233).shuffle(idxs)\n",
    "\n",
    "rs = []\n",
    "infos = []\n",
    "old_time = time.time()\n",
    "for i in idxs[:500]:\n",
    "    r, info = webthink(i, to_print=True)\n",
    "    rs.append(info['em'])\n",
    "    infos.append(info)\n",
    "    print(sum(rs), len(rs), sum(rs) / len(rs), (time.time() - old_time) / len(rs))\n",
    "    print('-----------')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
